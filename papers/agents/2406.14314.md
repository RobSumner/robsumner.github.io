# Identifying User Goals from UI Trajectories

[Arxiv](https://arxiv.org/abs/2406.14314)

## Summary

This paper introduces the task of identifying the goal of a user from the trajectory.

## Details

### Problem

Given a trajectory, the goal of this paper is to recover the user's original intent. This is effectively the inverse of the UI automation task (which takes as input a task and outputs a trajectory).

- The input to this task is a trajectory (sequence of screenshots), along with the actions taken at each step.
- The output is a description of the task being performed.

### Evaluation

One contribution from the paper is an evaluation methodology. Given the trajectory and target task description, the paper proposes using GPT-4V with the trajectories to assess if the target and predicted descriptions match. They find that this generally matches human evaluation scores, so can be used as a substitute.

### Prompts

The authors used a few tricks to help with prompting and inputs for GPT-4V:

- Use chain-of-thought reasoning to analyse the trajectory step-by-step.
- Used both zero-shot and few-shot prompting (including some examples).
- Drew red boxes around elements that the user interacted with to guide the model's attention and to break ambiguity.
- Truncated long web-pages to further focus the models attention.

### Mind2Web

The Mind2Web dataset is a set of task descriptions and example trajectories.

- Each trajectory step contains a screenshot, target element and operation. E.g. `Operation Type "London"; Element: textbox <Where to?>`
- Screenshots also show bounding boxes for the element that should be interacted with.
- Useful as it includes html, so could be processed to produce other tasks.
